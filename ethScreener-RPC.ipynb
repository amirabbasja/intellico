{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check blocks in provided range and find new tokens being initiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "import json\n",
    "from utils import *\n",
    "from web3 import Web3\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Get the config file\n",
    "configObj = ConfigManager(\"config.json\")\n",
    "appInfo, configData = configObj.load_config()\n",
    "nodeUrl = appInfo[\"alchemy_url\"]+appInfo[\"alchemy_key\"]\n",
    "\n",
    "# Checking the database state\n",
    "print(\"Checking database integrity ...\")\n",
    "db = dbUtils(user = \"postgres\", password = \"1234\", host  = \"localhost\", port =  \"5432\")\n",
    "# See if database exists\n",
    "if db.database_exists(\"screenerDB\"):\n",
    "    if not db.table_exists(\"screenerDB\", \"tokens\"):\n",
    "        print(\"Creating table 'tokens' in the database 'screenerDB'\")\n",
    "        # Cursor\n",
    "        db._connect_to_db(\"screenerDB\")\n",
    "        con = db._conn\n",
    "        cur = con.cursor()\n",
    "        \n",
    "        # Make a table for the new tokens\n",
    "        cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS tokens (\n",
    "                id SERIAL PRIMARY KEY,\n",
    "                address VARCHAR(255),\n",
    "                name VARCHAR(255),\n",
    "                symbol VARCHAR(255),\n",
    "                chain_name VARCHAR(255),\n",
    "                decimals INT,\n",
    "                inception_time BIGINT,\n",
    "                inception_block BIGINT,\n",
    "                total_supply VARCHAR(255)\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        con.commit()\n",
    "        \n",
    "        # close the connection\n",
    "        con.close()\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    raise Exception(f\"Database doesn't exist. First create the database with the name 'screenerDB'\")\n",
    "\n",
    "# Make the ETH blockchain handler\n",
    "web3 = Web3(Web3.HTTPProvider(nodeUrl))\n",
    "handler = ETH_Handler(web3)\n",
    "\n",
    "latest_block = handler.get_latest_block()\n",
    "\n",
    "# True only if the config file is new.\n",
    "if (configData['latest_block_checked'] == -1):\n",
    "    configData['latest_block_checked'] = latest_block\n",
    "\n",
    "print(f\"{latest_block['number'] - configData['latest_block_checked']} blocks to check\")\n",
    "\n",
    "nonTokens = pd.DataFrame(columns=['address'])\n",
    "\n",
    "try:\n",
    "    # Go through past blocks to find conteract creation events\n",
    "    for i in tqdm(range(configData['latest_block_checked'], latest_block['number']), total=latest_block['number'] - configData['latest_block_checked']):\n",
    "        block = web3.eth.get_block(i, True)\n",
    "        for tx in block.transactions:\n",
    "            if tx[\"to\"] == None:\n",
    "                tx_receipt = web3.eth.get_transaction_receipt(tx['hash'])\n",
    "                contract_address = tx_receipt['contractAddress']\n",
    "                contract_code = web3.eth.get_code(contract_address)\n",
    "                if contract_code != '0x':\n",
    "                    _details = handler.get_token_details(contract_address)\n",
    "\n",
    "                    if _details != None:\n",
    "                        if _details[\"name\"] != \"-\":\n",
    "                            _data = {\n",
    "                                'address': _details[\"address\"],\n",
    "                                'name': _details[\"name\"],\n",
    "                                'symbol': _details[\"symbol\"],\n",
    "                                'chain_name': \"Ethereum\",\n",
    "                                'decimals': _details[\"decimals\"],\n",
    "                                'inception_time': datetime.now().timestamp(),\n",
    "                                'inception_block': i,\n",
    "                                'total_supply': str(_details[\"total_supply\"])\n",
    "                            }\n",
    "                            state, _ = db.insert_row(appInfo[\"database_name\"], \"tokens\", _data)\n",
    "                            \n",
    "                            # Raise an error if couldn't add to the database \n",
    "                            if not state:\n",
    "                                raise Exception(f\"Error in inserting token {contract_address} in the database\")\n",
    "                        else:\n",
    "                            # DELETE\n",
    "                            nonTokens = pd.concat([nonTokens, pd.DataFrame([contract_address], columns=['address'])])\n",
    "                            pass\n",
    "        configData['latest_block_checked'] = i\n",
    "        configObj.save_config(configData)\n",
    "        nonTokens.to_csv(\"nonTokens.csv\") # DELETE\n",
    "\n",
    "        time.sleep(0.02)\n",
    "    \n",
    "    # Update the latest block checked\n",
    "    configData['latest_block_checked'] = i\n",
    "    configObj.save_config(configData)\n",
    "    print(\"Database updated successfully\")\n",
    "    \n",
    "    # DELETE\n",
    "    nonTokens.to_csv(\"nonTokens.csv\")\n",
    "    \n",
    "except Exception as e:\n",
    "    configData['latest_block_checked'] =  i\n",
    "    configObj.save_config(configData)\n",
    "    print(f\"Error in block {i}\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download timestamp of blocks on ethereum and save them to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv\n",
    "from dotenv import load_dotenv \n",
    "import json\n",
    "from utils import *\n",
    "from web3 import Web3\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the config file\n",
    "configObj = ConfigManager(\"config.json\")\n",
    "appInfo, configData = configObj.load_config()\n",
    "nodeUrl = appInfo[\"alchemy_url\"]+appInfo[\"alchemy_key\"]\n",
    "\n",
    "def __getBlockTimestamp(blockNumber:int, web3Obj:Web3):\n",
    "    \"\"\"\n",
    "    Gets an ethereum block and returns its timestamp and datetime as a dictionary \n",
    "    \"\"\"\n",
    "    __block = web3Obj.eth.get_block(blockNumber, False)\n",
    "    return {\n",
    "        \"block\": blockNumber, \n",
    "        \"timestamp\": __block[\"timestamp\"], \n",
    "        \"datetime\": datetime.fromtimestamp(__block[\"timestamp\"])\n",
    "        }\n",
    "    \n",
    "\n",
    "def __getFiles(path:str):\n",
    "    \"\"\"\n",
    "    Gets the CSV files in a folder\n",
    "    \n",
    "    Returns:\n",
    "        A list of lists [[start block - end block]]\n",
    "        A dictionary with smallest block number and its respective file name\n",
    "        A dictionary with oldest block number and its respective file name\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    result = []\n",
    "    __maxNumber = 0\n",
    "    __maxNumber_file = \"\"\n",
    "    __minNumber = 99999999999\n",
    "    __minNumber_file = \"\"\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            parts = file.split('-')\n",
    "            if len(parts) == 2:\n",
    "                x = int(parts[0])\n",
    "                m = int(parts[1].replace('.csv', ''))\n",
    "                result.append([x, m])\n",
    "                \n",
    "                if __maxNumber < m: __maxNumber = m; __maxNumber_file = file\n",
    "                if x < __minNumber: __minNumber = x; __minNumber_file = file\n",
    "    \n",
    "    return result, {\"block_number\":__minNumber,\"file\":__minNumber_file},{\"block_number\":__maxNumber,\"file\":__maxNumber_file}\n",
    "\n",
    "def __makeCSV(path,startBlockNumber,endBlockNumber,web3, reverse = False):\n",
    "    \"\"\"\n",
    "    Makes a fresh csv file and add blocks to it.\n",
    "    \n",
    "    Returns:\n",
    "        Newly made file's name.\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        ['block', 'timestamp', 'datetime'],\n",
    "    ]\n",
    "    if startBlockNumber < endBlockNumber:\n",
    "        for i in range(startBlockNumber,endBlockNumber+1):\n",
    "            __tmp = __getBlockTimestamp(i,web3)\n",
    "            data.append([__tmp[\"block\"], __tmp[\"timestamp\"], __tmp[\"datetime\"]])\n",
    "    \n",
    "    \n",
    "    if reverse:\n",
    "        data.reverse()\n",
    "        data.insert(0, data.pop())\n",
    "        \n",
    "    with open(os.path.join(path,f\"{startBlockNumber}-{endBlockNumber}.csv\"), 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data)\n",
    "        f.close()\n",
    "        return f\"{startBlockNumber}-{endBlockNumber}.csv\"\n",
    "\n",
    "def getBlockTimestamps(path:str, direction:str, web3Obj:Web3):\n",
    "    \"\"\"\n",
    "    Gets block timestamps ands saves them in a csv file in passed path.\n",
    "    Each CSV file contains ethereum block numbers, timestamps and datetimes. Blocks \n",
    "    get older as we move down the csv file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining the super parameters\n",
    "    __Default_Start_Block = 21500000 # The first file's starting block (If there are no files in path)\n",
    "    __Batch_length = 100000 # The amount of blocks each csv file can contain\n",
    "    __Target_File = \"\" # The file which newly downloaded blocks are gonna be added to\n",
    "    __Save_Batch_Length = 4000 # Save blocks in the csv file batches of this length\n",
    "    __STOP = False # Weather to stop the downloading process\n",
    "    __STOP_Sub_Batch = False # For checking i with latest block number to see if we have reached the most recent block\n",
    "    \n",
    "    # Get previously saved csv files\n",
    "    if os.path.exists(path):\n",
    "        \n",
    "        # Get previous files\n",
    "        lstFiles = __getFiles(path)\n",
    "        \n",
    "        if len(lstFiles[0]) != 0:\n",
    "            __n1 = lstFiles[1]['block_number']\n",
    "            __n2 = lstFiles[2]['block_number']\n",
    "            print(f\"Found {len(lstFiles[0])} records. Oldest block: {__n1}, most recent block: {__n2}\")\n",
    "        else:\n",
    "            print(f\"No files exist in the directory, making teh first file. Starting from block {__Default_Start_Block}\")\n",
    "            __makeCSV(path,__Default_Start_Block,__Default_Start_Block+1,web3Obj)\n",
    "            __n1 = __Default_Start_Block\n",
    "            __n2 = __Default_Start_Block+1\n",
    "            lstFiles = __getFiles(path)\n",
    "                \n",
    "        # Set the starting block parameter\n",
    "        if direction == \"forward\":\n",
    "            \n",
    "            # Get the target csv file to save the block data\n",
    "            if lstFiles[2][\"block_number\"] % __Batch_length != __Batch_length - 1:\n",
    "                __Target_File = os.path.join(path, lstFiles[2][\"file\"])\n",
    "                __tmp = lstFiles[2][\"block_number\"]\n",
    "                print(f\"Catching up with latest block. Approx, {web3Obj.eth.block_number - __tmp} blocks to chatch up with ...\")\n",
    "            else:\n",
    "                # Happens when the most recent file is full\n",
    "                print(f\"Most recent file is full. Making a new file for blocks bigger than {__n2}\")\n",
    "                __name = __makeCSV(path,lstFiles[2][\"block_number\"]+1,lstFiles[2][\"block_number\"]+2,web3Obj)\n",
    "                __Target_File = os.path.join(path, __name)\n",
    "            \n",
    "            # First and Last block to catch\n",
    "            __Download_Start_Block = int(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[1])+1\n",
    "            __Download_End_Block = int(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[0]) + __Batch_length - 1\n",
    "            \n",
    "            while not __STOP:\n",
    "                print(f\"Downloading blocks {__Download_Start_Block} to {__Download_End_Block}\")\n",
    "                for batch in range(__Download_Start_Block,__Download_End_Block+1,__Save_Batch_Length):    \n",
    "                    # Open the target file\n",
    "                    with open(__Target_File, 'a', newline='') as f:\n",
    "                        __data = []\n",
    "                        writer = csv.writer(f)\n",
    "                        \n",
    "                        # See if the current sub-batch range has the latest block in it\n",
    "                        if batch <= web3Obj.eth.block_number and web3Obj.eth.block_number <= __Download_End_Block:\n",
    "                            __STOP = True\n",
    "                            __STOP_Sub_Batch = True\n",
    "                        \n",
    "                        for i in tqdm(range(batch, min(batch + __Save_Batch_Length, __Download_End_Block+1))):\n",
    "                            __tmp = __getBlockTimestamp(i,web3)\n",
    "                            __data.append([__tmp[\"block\"], __tmp[\"timestamp\"], __tmp[\"datetime\"]])\n",
    "                            \n",
    "                            # Is true only if the current sub-range range(batch, min(batch + __Save_Batch_Length, __Download_End_Block+1))\n",
    "                            # contains the latest block number\n",
    "                            if __STOP_Sub_Batch:\n",
    "                                if i == web3Obj.eth.block_number: \n",
    "                                    print(f\"Caught up with latest block {i}\")\n",
    "                                    break\n",
    "                        \n",
    "                        # Write the appended data to the file and close it. Then rename it.\n",
    "                        writer.writerows(__data)\n",
    "                        f.close()\n",
    "                        \n",
    "                        # Rename the file after saving new data in it\n",
    "                        os.rename(__Target_File, __Target_File.replace(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[1], str(i)))\n",
    "                        \n",
    "                        # Change the parameter for opening the target file in the next iteration\n",
    "                        __Target_File = __Target_File.replace(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[1], str(i))\n",
    "\n",
    "                # Batch finished. Make a new file for next batch.\n",
    "                __Target_File = os.path.join(path, __makeCSV(path,i + 1, i + 2,web3Obj))\n",
    "                __Download_Start_Block = i + 1\n",
    "                __Download_End_Block = __Download_Start_Block + __Batch_length - 1\n",
    "                \n",
    "                time.sleep(1)\n",
    "                \n",
    "        elif direction == \"backward\":\n",
    "            \n",
    "            # Get the target csv file to save the block data\n",
    "            if lstFiles[1][\"block_number\"] % __Batch_length != 0:\n",
    "                __Target_File = os.path.join(path, lstFiles[1][\"file\"])\n",
    "            else:\n",
    "                # Happens when the most recent file is full\n",
    "                print(f\"Most recent file is full. Making a new file for blocks smaller than {__n1}\")\n",
    "                __name = __makeCSV(path,lstFiles[1][\"block_number\"]-2,lstFiles[1][\"block_number\"]-1,web3Obj,True)\n",
    "                __Target_File = os.path.join(path, __name)\n",
    "            \n",
    "            # First and Last block to catch\n",
    "            __Download_Start_Block = int(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[1]) - __Batch_length + 1\n",
    "            __Download_End_Block = int(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[0])\n",
    "            \n",
    "            \n",
    "            while not __STOP:\n",
    "                print(f\"Downloading blocks {__Download_Start_Block} to {__Download_End_Block}\")\n",
    "                for batch in range(__Download_End_Block, __Download_Start_Block-1, - __Save_Batch_Length):     \n",
    "                    # Open the target file\n",
    "                    with open(__Target_File, 'a', newline='') as f:\n",
    "                        __data = []\n",
    "                        writer = csv.writer(f)\n",
    "                        \n",
    "                        for i in tqdm(range(batch - 1, max(batch - __Save_Batch_Length, __Download_Start_Block-1), -1)):\n",
    "                            __tmp = __getBlockTimestamp(i,web3)\n",
    "                            __data.append([__tmp[\"block\"], __tmp[\"timestamp\"], __tmp[\"datetime\"]])\n",
    "                        \n",
    "                        # Write the appended data to the file and close it. Then rename it.\n",
    "                        writer.writerows(__data)\n",
    "                        f.close()\n",
    "                        \n",
    "                        # Rename the file after saving new data in it\n",
    "                        os.rename(__Target_File, __Target_File.replace(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[0], str(i)))\n",
    "                        \n",
    "                        # Change the parameter for opening the target file in the next iteration\n",
    "                        __Target_File = __Target_File.replace(os.path.basename(__Target_File).replace(\".csv\",\"\").split(\"-\")[0], str(i))\n",
    "\n",
    "                # Batch finished. Make a new file for next batch.\n",
    "                __Target_File = os.path.join(path, __makeCSV(path, i - 2, i - 1,web3Obj,True))\n",
    "                __Download_Start_Block = i - __Batch_length\n",
    "                __Download_End_Block = i - 2\n",
    "                \n",
    "                time.sleep(1)\n",
    "            \n",
    "        \n",
    "    else:\n",
    "        raise Exception(f\"Path: {path}  Does not exist.\")\n",
    "\n",
    "    \n",
    "# Make the ETH blockchain handler\n",
    "web3 = Web3(Web3.HTTPProvider(nodeUrl))\n",
    "handler = ETH_Handler(web3)\n",
    "# __getFiles(\"./resources\")\n",
    "getBlockTimestamps(\"./resources\", \"backward\", web3Obj = web3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Connect to the database\n",
    "# db = dbUtils(user = \"postgres\", password = \"1234\", host  = \"localhost\", port =  \"5432\")\n",
    "\n",
    "# # See if database exists\n",
    "# if db.database_exists(\"screenerDB\"):\n",
    "#     if not db.table_exists(\"screenerDB\", \"tokens\"):\n",
    "#         print(\"Creating table 'tokens' in the database 'screenerDB'\")\n",
    "#         # Cursor\n",
    "#         db._connect_to_db(\"screenerDB\")\n",
    "#         con = db._conn\n",
    "#         cur = con.cursor()\n",
    "        \n",
    "#         # Make a table for the new tokens\n",
    "#         cur.execute(\"\"\"\n",
    "#             CREATE TABLE IF NOT EXISTS tokens (\n",
    "#                 id SERIAL PRIMARY KEY,\n",
    "#                 address VARCHAR(255),\n",
    "#                 name VARCHAR(255),\n",
    "#                 symbol VARCHAR(255),\n",
    "#                 chain_name VARCHAR(255),\n",
    "#                 decimals INT,\n",
    "#                 inception_time BIGINT,\n",
    "#                 inception_block BIGINT,\n",
    "#                 total_supply VARCHAR(255)\n",
    "#             )\n",
    "#         \"\"\")\n",
    "        \n",
    "#         con.commit()\n",
    "        \n",
    "#         # close the connection\n",
    "#         con.close()\n",
    "#     else:\n",
    "#         pass\n",
    "# else:\n",
    "#     print(f\"Database doesn't exist. First create the database with the name 'screenerDB'\")\n",
    "\n",
    "\n",
    "\n",
    "# # Insert row\n",
    "# from datetime import datetime\n",
    "# from utils import dbUtils\n",
    "# db = dbUtils(user = \"postgres\", password = \"1234\", host  = \"localhost\", port =  \"5432\")\n",
    "# data = {\n",
    "#     'address': \"0x248A791B9b3E0e17641A5D0E306B8485403432a9\",\n",
    "#     'name': \"PopKitty\",\n",
    "#     'symbol': \"POPKI\",\n",
    "#     'chain_name': \"Ethereum\",\n",
    "#     'decimals': 9,\n",
    "#     'inception_time': datetime.now().timestamp(),\n",
    "#     'inception_block': 2155211421,\n",
    "#     'total_supply': str(100000000000000000000000000)\n",
    "# }\n",
    "# db.insert_row(\"screenerDB\", \"tokens\", data)\n",
    "\n",
    "# # Delete row\n",
    "# success, count = db.delete_row(appInfo[\"database_name\"], \"tokens\", \"id = %s\", 3 )\n",
    "\n",
    "# # Update row\n",
    "# data[\"address\"] = \"0x111\"\n",
    "# db.update_row(\n",
    "#     appInfo[\"database_name\"],\n",
    "#     \"tokens\",\n",
    "#     data,\n",
    "#     \"id = %s\",\n",
    "#     1\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
